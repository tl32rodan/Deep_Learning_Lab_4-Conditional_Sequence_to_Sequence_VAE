{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "from VAE import *\n",
    "from scores import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = load_data('./data/train.txt')\n",
    "test_vocab = load_data('./data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get different tense pairs\n",
    "### !Basically unused in conditional VAE training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tense_paris(train_vocab, input_tense, target_tense):\n",
    "    pairs = []\n",
    "\n",
    "    for vocabs in train_vocab:\n",
    "        pairs.append((vocabs[input_tense],vocabs[target_tense]))\n",
    "        \n",
    "    return pairs  \n",
    "\n",
    "# Simple Present -> Third Person\n",
    "train_st_tp  = get_tense_paris(train_vocab, 0, 1)\n",
    "# Simple Present -> Present Progressive\n",
    "train_st_pp  = get_tense_paris(train_vocab, 0, 2)\n",
    "# Simple Present -> Past\n",
    "train_st_past  = get_tense_paris(train_vocab, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 28 #The number of vocabulary\n",
    "SOS_token = 0\n",
    "EOS_token = vocab_size-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Hyper Parameters----------#\n",
    "hidden_size = 256\n",
    "latent_size = 64\n",
    "teacher_forcing_ratio = 0.75\n",
    "empty_input_ratio = 0.1\n",
    "KLD_weight = 0.0\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_from_str(target):\n",
    "    ord_a = ord('a')\n",
    "    seq = [ord(c) - ord_a + 1 for c in target]\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def str_from_tensor(target):\n",
    "    seq = ''\n",
    "    for output in target:\n",
    "        _, c = output.topk(1)\n",
    "        seq += chr(c+ord('a')-1)\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use KL annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_annealing(current_iter, policy = 'mono', reach_max = 3000, period = 6000):\n",
    "    if policy == 'mono':\n",
    "        beta = 1 if current_iter >= reach_max else current_iter/reach_max\n",
    "    elif policy == 'cyclical':\n",
    "        beta = 1 if current_iter%period >= reach_max else (current_iter%period)/reach_max\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 4 tense using simple present (for BLEU-4 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_by_simple(vae_model, data_tuple):\n",
    "    pred_tuple = []\n",
    "    \n",
    "    vae_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(4):\n",
    "            input_tense = 0  # Input: simple present\n",
    "            target_tense = i # Target: 4 tense results\n",
    "            input_seq, target_seq = (seq_from_str(data_tuple[input_tense]),seq_from_str(data_tuple[target_tense])) \n",
    "            \n",
    "            # Initialize hidden feature\n",
    "            hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, input_tense, target_tense)\n",
    "            \n",
    "            pred_seq = str_from_tensor(result)\n",
    "            pred_tuple.append(pred_seq[:-1])\n",
    "            \n",
    "    return pred_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_condVAE(vae_model, input_seq, input_cond, target_seq, target_cond, use_teacher_forcing, optimizer, \\\n",
    "                  criterion_CE, criterion_KLD, kl_annealing_beta = 1):    \n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize hidden feature\n",
    "    hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "        \n",
    "    # Run model\n",
    "    optimizer.zero_grad()\n",
    "    if use_teacher_forcing:\n",
    "        # input_cond is encoder condition; targer_cond is decoder condition\n",
    "        result, mu, logvar = vae_model(input_seq, hidden, input_cond, target_cond, use_teacher_forcing, target_seq)\n",
    "    else:\n",
    "        result, mu, logvar = vae_model(input_seq, hidden, input_cond, target_cond, use_teacher_forcing, None)\n",
    "            \n",
    "            \n",
    "    # Ground truth should have EOS in the end\n",
    "    target_seq.append(EOS_token)\n",
    "    \n",
    "    # Calculate loss\n",
    "    # First, we should strim the sequences by the length of smaller one\n",
    "    min_len = min(len(target_seq),len(result))\n",
    "        \n",
    "    # hat_y need not to do one-hot encoding\n",
    "    hat_y = result[:min_len]\n",
    "    y = torch.tensor(target_seq[:min_len], device=device)\n",
    "        \n",
    "    ce_loss = criterion_CE(hat_y, y)\n",
    "    kld_loss = criterion_KLD(mu, logvar)\n",
    "    kld_loss = kl_annealing_beta * kld_loss # KL annealing\n",
    "    \n",
    "    loss = ce_loss + kld_loss\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return ce_loss.item(), kld_loss.item(), hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIter_condVAE(vae_model, data, n_iters, print_every=1000, save_every=1000, record_every=1000,\n",
    "                      learning_rate=0.01, teacher_forcing_ratio = 1.0, \n",
    "                      optimizer = None, scheduler = None,\n",
    "                      criterion_CE = VAE_Loss_CE, criterion_KLD = VAE_Loss_KLD,\n",
    "                      date = '', kl_annealing = 'mono'):\n",
    "    '''\n",
    "        data: A list of 4-tuple\n",
    "              the tense order should be : (simple present, third person, present progressive, past)\n",
    "    '''\n",
    "    loss_list = []\n",
    "    ce_loss_list = []\n",
    "    kld_loss_list = []\n",
    "    bleu_list = []\n",
    "  \n",
    "    # Check optimizer; default: SGD\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.SGD(vae_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for i in range(n_iters): \n",
    "        \n",
    "        # Randomly generate training pairs from data\n",
    "        chosen_data = random.choice(data)\n",
    "        input_tense = random.randint(0,3) # Draw input tense\n",
    "        #target_tense = random.randint(0,3) # Draw target tense\n",
    "        target_tense = input_tense\n",
    "        input_seq = seq_from_str(chosen_data[input_tense])\n",
    "        target_seq = seq_from_str(chosen_data[target_tense])                  \n",
    "        \n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        \n",
    "        \n",
    "        # Calculate BLEU-4 score\n",
    "        # Should execute before updating the model\n",
    "        if (i+1) % record_every == 0 or (i+1) % print_every == 0:\n",
    "            pred = infer_by_simple(vae_model, chosen_data)\n",
    "            bleu_score = compute_bleu(pred, chosen_data)\n",
    "        \n",
    "        # KL annealing's beta\n",
    "        beta = KL_annealing(i, policy=kl_annealing)\n",
    "        \n",
    "        # Training\n",
    "        \n",
    "        vae_model.train()\n",
    "        ce_loss, kld_loss, hat_y = train_condVAE(vae_model, input_seq, input_tense, target_seq, target_tense,\\\n",
    "                             use_teacher_forcing, optimizer, criterion_CE, criterion_KLD, beta)\n",
    "    \n",
    "        # Loss\n",
    "        loss = ce_loss + kld_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Convert output to str\n",
    "        pred_seq = str_from_tensor(hat_y)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        if (i+1) % record_every == 0:\n",
    "            loss_list.append(loss)\n",
    "            ce_loss_list.append(ce_loss)\n",
    "            kld_loss_list.append(kld_loss)\n",
    "            bleu_list.append(bleu_score)\n",
    "            \n",
    "        if (i+1) % print_every == 0:\n",
    "            print('-----------------')\n",
    "            print('Iter %d: loss = %.4f' % (i+1, loss))\n",
    "            print('ce_loss = ', ce_loss)\n",
    "            print('kld_loss = ', kld_loss)\n",
    "            print('    ==================')\n",
    "            print('    pred = ', pred)\n",
    "            print('    chosen_data = ', chosen_data)\n",
    "            print('    BLEU-4 score = ', bleu_score)\n",
    "            print('    ==================')\n",
    "            print('input_seq = ', chosen_data[input_tense])\n",
    "            print('pred_seq = ', pred_seq)\n",
    "            print('target_seq = ', chosen_data[target_tense])\n",
    "            \n",
    "        if (i+1) % save_every == 0:\n",
    "            torch.save(vae_model,'./models/condVAE_'+str(i+1)+date)\n",
    "    \n",
    "    return loss_list, ce_loss_list, kld_loss_list, bleu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vae = CondVAE(vocab_size, hidden_size, vocab_size, teacher_forcing_ratio).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(my_vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Iter 1000: loss = 2.8532\n",
      "ce_loss =  2.852135419845581\n",
      "kld_loss =  0.0010822410695254803\n",
      "    ==================\n",
      "    pred =  ['sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese']\n",
      "    chosen_data =  ['drag', 'drags', 'dragging', 'dragged']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  dragged\n",
      "pred_seq =  seeeees\n",
      "target_seq =  dragged\n",
      "-----------------\n",
      "Iter 2000: loss = 2.5671\n",
      "ce_loss =  2.5646588802337646\n",
      "kld_loss =  0.002437703311443329\n",
      "    ==================\n",
      "    pred =  ['sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese']\n",
      "    chosen_data =  ['arouse', 'arouses', 'arousing', 'aroused']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  arouse\n",
      "pred_seq =  sreene\n",
      "target_seq =  arouse\n",
      "-----------------\n",
      "Iter 3000: loss = 2.1872\n",
      "ce_loss =  2.186622142791748\n",
      "kld_loss =  0.0005928387399762869\n",
      "    ==================\n",
      "    pred =  ['sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese', 'sesesesesesesesesesesese']\n",
      "    chosen_data =  ['come', 'comes', 'coming', 'came']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  comes\n",
      "pred_seq =  sores\n",
      "target_seq =  comes\n",
      "-----------------\n",
      "Iter 4000: loss = 2.7667\n",
      "ce_loss =  2.764782190322876\n",
      "kld_loss =  0.0019456446170806885\n",
      "    ==================\n",
      "    pred =  ['sesede', 'bedede', 'bedede', 'bedede']\n",
      "    chosen_data =  ['manifest', 'manifests', 'manifesting', 'manifested']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  manifest\n",
      "pred_seq =  setgnede\n",
      "target_seq =  manifest\n",
      "-----------------\n",
      "Iter 5000: loss = 2.7696\n",
      "ce_loss =  2.7685275077819824\n",
      "kld_loss =  0.001085907220840454\n",
      "    ==================\n",
      "    pred =  ['corededed', 'sededed', 'sededed', 'corededed']\n",
      "    chosen_data =  ['misrepresent', 'misrepresents', 'misrepresenting', 'misrepresented']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  misrepresents\n",
      "pred_seq =  corededed{\n",
      "target_seq =  misrepresents\n",
      "-----------------\n",
      "Iter 6000: loss = 2.5003\n",
      "ce_loss =  2.50002384185791\n",
      "kld_loss =  0.00029355287551879883\n",
      "    ==================\n",
      "    pred =  ['coresese', 'desese', 'coresese', 'derese']\n",
      "    chosen_data =  ['sidle', 'sidles', 'sidling', 'sidled']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  sidles\n",
      "pred_seq =  denees\n",
      "target_seq =  sidles\n",
      "-----------------\n",
      "Iter 7000: loss = 2.6104\n",
      "ce_loss =  2.610062837600708\n",
      "kld_loss =  0.00035753846168518066\n",
      "    ==================\n",
      "    pred =  ['sereded', 'sereded', 'sereded', 'sereded']\n",
      "    chosen_data =  ['kiss', 'kisses', 'kissing', 'kissed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  kisses\n",
      "pred_seq =  seneed\n",
      "target_seq =  kisses\n",
      "-----------------\n",
      "Iter 8000: loss = 2.2262\n",
      "ce_loss =  2.2256271839141846\n",
      "kld_loss =  0.0005637705326080322\n",
      "    ==================\n",
      "    pred =  ['seeded', 'seeded', 'seeded', 'seeded']\n",
      "    chosen_data =  ['express', 'expresses', 'expressing', 'expressed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  expresses\n",
      "pred_seq =  saieeeeee\n",
      "target_seq =  expresses\n",
      "-----------------\n",
      "Iter 9000: loss = 2.3309\n",
      "ce_loss =  2.329333543777466\n",
      "kld_loss =  0.001587986946105957\n",
      "    ==================\n",
      "    pred =  ['bereded', 'sereded', 'sereded', 'sereded']\n",
      "    chosen_data =  ['choose', 'chooses', 'choosing', 'chose']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  choose\n",
      "pred_seq =  soenne\n",
      "target_seq =  choose\n",
      "-----------------\n",
      "Iter 10000: loss = 2.2876\n",
      "ce_loss =  2.2873215675354004\n",
      "kld_loss =  0.0002586245536804199\n",
      "    ==================\n",
      "    pred =  ['sereded', 'sereded', 'sereded', 'sereded']\n",
      "    chosen_data =  ['remember', 'remembers', 'remembering', 'remembered']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  remembered\n",
      "pred_seq =  seaidieded\n",
      "target_seq =  remembered\n",
      "-----------------\n",
      "Iter 11000: loss = 2.3202\n",
      "ce_loss =  2.319471836090088\n",
      "kld_loss =  0.0007162392139434814\n",
      "    ==================\n",
      "    pred =  ['corested', 'surested', 'surested', 'surested']\n",
      "    chosen_data =  ['shut', 'shuts', 'shutting', 'shut']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  shuts\n",
      "pred_seq =  suare\n",
      "target_seq =  shuts\n",
      "-----------------\n",
      "Iter 12000: loss = 2.4398\n",
      "ce_loss =  2.4376449584960938\n",
      "kld_loss =  0.00210687518119812\n",
      "    ==================\n",
      "    pred =  ['seree', 'seree', 'seree', 'seree']\n",
      "    chosen_data =  ['become', 'becomes', 'becoming', 'became']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  became\n",
      "pred_seq =  serhte\n",
      "target_seq =  became\n",
      "-----------------\n",
      "Iter 13000: loss = 2.2889\n",
      "ce_loss =  2.2884867191314697\n",
      "kld_loss =  0.0003745853900909424\n",
      "    ==================\n",
      "    pred =  ['conted', 'conted', 'conted', 'conted']\n",
      "    chosen_data =  ['feint', 'feints', 'feinting', 'feinted']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  feints\n",
      "pred_seq =  cllnge\n",
      "target_seq =  feints\n",
      "-----------------\n",
      "Iter 14000: loss = 3.1126\n",
      "ce_loss =  3.10247540473938\n",
      "kld_loss =  0.010103285312652588\n",
      "    ==================\n",
      "    pred =  ['conteded', 'seated', 'seated', 'seated']\n",
      "    chosen_data =  ['undo', 'undoes', 'undoing', 'undid']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  undo\n",
      "pred_seq =  srte\n",
      "target_seq =  undo\n",
      "-----------------\n",
      "Iter 15000: loss = 2.7884\n",
      "ce_loss =  2.7877585887908936\n",
      "kld_loss =  0.0006460845470428467\n",
      "    ==================\n",
      "    pred =  ['sured', 'sured', 'sured', 'sured']\n",
      "    chosen_data =  ['congeal', 'congeals', 'congealing', 'congealed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  congeals\n",
      "pred_seq =  sured{\n",
      "target_seq =  congeals\n",
      "-----------------\n",
      "Iter 16000: loss = 2.8308\n",
      "ce_loss =  2.8290529251098633\n",
      "kld_loss =  0.0017152130603790283\n",
      "    ==================\n",
      "    pred =  ['senterted', 'senterted', 'condeded', 'areste']\n",
      "    chosen_data =  ['accompany', 'accompanies', 'accompanying', 'accompanied']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  accompany\n",
      "pred_seq =  srkhneetd\n",
      "target_seq =  accompany\n",
      "-----------------\n",
      "Iter 17000: loss = 2.2420\n",
      "ce_loss =  2.2418103218078613\n",
      "kld_loss =  0.0002333521842956543\n",
      "    ==================\n",
      "    pred =  ['deresee', 'beatese', 'beatese', 'searese']\n",
      "    chosen_data =  ['finalize', 'finalizes', 'finalizing', 'finalized']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  finalized\n",
      "pred_seq =  sangtined\n",
      "target_seq =  finalized\n",
      "-----------------\n",
      "Iter 18000: loss = 2.1786\n",
      "ce_loss =  2.1781516075134277\n",
      "kld_loss =  0.0004544556140899658\n",
      "    ==================\n",
      "    pred =  ['conteringed', 'conteringed', 'conteringed', 'conteringed']\n",
      "    chosen_data =  ['bother', 'bothers', 'bothering', 'bothered']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  bothers\n",
      "pred_seq =  cerreds\n",
      "target_seq =  bothers\n",
      "-----------------\n",
      "Iter 19000: loss = 1.4629\n",
      "ce_loss =  1.462889313697815\n",
      "kld_loss =  4.601478576660156e-05\n",
      "    ==================\n",
      "    pred =  ['seeringed', 'seeringed', 'seeringed', 'andedse']\n",
      "    chosen_data =  ['sing', 'sings', 'singing', 'sang']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  singing\n",
      "pred_seq =  sengeng\n",
      "target_seq =  singing\n",
      "-----------------\n",
      "Iter 20000: loss = 3.2829\n",
      "ce_loss =  3.2820775508880615\n",
      "kld_loss =  0.000791698694229126\n",
      "    ==================\n",
      "    pred =  ['disteree', 'seeinged', 'belinged', 'disteree']\n",
      "    chosen_data =  ['double', 'doubles', 'doubling', 'doubled']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  double\n",
      "pred_seq =  distere\n",
      "target_seq =  double\n",
      "-----------------\n",
      "Iter 21000: loss = 2.1950\n",
      "ce_loss =  2.194807291030884\n",
      "kld_loss =  0.00021755695343017578\n",
      "    ==================\n",
      "    pred =  ['setree', 'seetre', 'setree', 'setree']\n",
      "    chosen_data =  ['arraign', 'arraigns', 'arraigning', 'arraigned']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  arraigned\n",
      "pred_seq =  sseetnegd\n",
      "target_seq =  arraigned\n",
      "-----------------\n",
      "Iter 22000: loss = 2.1413\n",
      "ce_loss =  2.1406240463256836\n",
      "kld_loss =  0.0006479620933532715\n",
      "    ==================\n",
      "    pred =  ['seeringed', 'seeringed', 'seeringed', 'seeringed']\n",
      "    chosen_data =  ['bethink', 'bethinks', 'bethinking', 'bethought']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  bethinks\n",
      "pred_seq =  serrenge\n",
      "target_seq =  bethinks\n",
      "-----------------\n",
      "Iter 23000: loss = 1.7950\n",
      "ce_loss =  1.7949644327163696\n",
      "kld_loss =  5.59389591217041e-05\n",
      "    ==================\n",
      "    pred =  ['sealinged', 'sealinged', 'sealinged', 'sealinged']\n",
      "    chosen_data =  ['assign', 'assigns', 'assigning', 'assigned']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  assigning\n",
      "pred_seq =  sctesning\n",
      "target_seq =  assigning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Iter 24000: loss = 3.0130\n",
      "ce_loss =  3.0123958587646484\n",
      "kld_loss =  0.0005922913551330566\n",
      "    ==================\n",
      "    pred =  ['consee', 'consee', 'consee', 'consee']\n",
      "    chosen_data =  ['object', 'objects', 'objecting', 'objected']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  object\n",
      "pred_seq =  cnlert\n",
      "target_seq =  object\n",
      "-----------------\n",
      "Iter 25000: loss = 1.8364\n",
      "ce_loss =  1.8363333940505981\n",
      "kld_loss =  5.9932470321655273e-05\n",
      "    ==================\n",
      "    pred =  ['searended', 'consended', 'searended', 'seetere']\n",
      "    chosen_data =  ['extract', 'extracts', 'extracting', 'extracted']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  extracted\n",
      "pred_seq =  sxpeetked\n",
      "target_seq =  extracted\n",
      "-----------------\n",
      "Iter 26000: loss = 2.4252\n",
      "ce_loss =  2.4243199825286865\n",
      "kld_loss =  0.0008727014064788818\n",
      "    ==================\n",
      "    pred =  ['snounted', 'surese', 'snounted', 'snounted']\n",
      "    chosen_data =  ['give', 'gives', 'giving', 'gave']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  gave\n",
      "pred_seq =  srre\n",
      "target_seq =  gave\n",
      "-----------------\n",
      "Iter 27000: loss = 1.9796\n",
      "ce_loss =  1.9795373678207397\n",
      "kld_loss =  3.272294998168945e-05\n",
      "    ==================\n",
      "    pred =  ['conte', 'approwinged', 'approwinged', 'approwinged']\n",
      "    chosen_data =  ['hail', 'hails', 'hailing', 'hailed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  hailing\n",
      "pred_seq =  aartlng\n",
      "target_seq =  hailing\n",
      "-----------------\n",
      "Iter 28000: loss = 1.8253\n",
      "ce_loss =  1.825154185295105\n",
      "kld_loss =  0.00018641352653503418\n",
      "    ==================\n",
      "    pred =  ['sentinged', 'seerte', 'seerte', 'seerte']\n",
      "    chosen_data =  ['blush', 'blushes', 'blushing', 'blushed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  blushes\n",
      "pred_seq =  seasted\n",
      "target_seq =  blushes\n",
      "-----------------\n",
      "Iter 29000: loss = 2.0603\n",
      "ce_loss =  2.060213088989258\n",
      "kld_loss =  0.00010091066360473633\n",
      "    ==================\n",
      "    pred =  ['surree', 'sigged', 'sigged', 'sigleded']\n",
      "    chosen_data =  ['feature', 'features', 'featuring', 'featured']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  featured\n",
      "pred_seq =  slrrered\n",
      "target_seq =  featured\n",
      "-----------------\n",
      "Iter 30000: loss = 2.4057\n",
      "ce_loss =  2.405151844024658\n",
      "kld_loss =  0.0005138516426086426\n",
      "    ==================\n",
      "    pred =  ['setre', 'setre', 'setre', 'setre']\n",
      "    chosen_data =  ['swallow', 'swallows', 'swallowing', 'swallowed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  swallow\n",
      "pred_seq =  seinien\n",
      "target_seq =  swallow\n",
      "-----------------\n",
      "Iter 31000: loss = 2.3696\n",
      "ce_loss =  2.368767261505127\n",
      "kld_loss =  0.000833660364151001\n",
      "    ==================\n",
      "    pred =  ['astrandedededededededede', 'contringed', 'contringed', 'contringed']\n",
      "    chosen_data =  ['disagree', 'disagrees', 'disagreeing', 'disagreed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  disagree\n",
      "pred_seq =  cestteed\n",
      "target_seq =  disagree\n",
      "-----------------\n",
      "Iter 32000: loss = 1.6355\n",
      "ce_loss =  1.6354339122772217\n",
      "kld_loss =  4.661083221435547e-05\n",
      "    ==================\n",
      "    pred =  ['compleded', 'compleded', 'seeee', 'seare']\n",
      "    chosen_data =  ['pick', 'picks', 'picking', 'picked']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  picking\n",
      "pred_seq =  srrkeng\n",
      "target_seq =  picking\n",
      "-----------------\n",
      "Iter 33000: loss = 2.1042\n",
      "ce_loss =  2.104191541671753\n",
      "kld_loss =  4.9173831939697266e-05\n",
      "    ==================\n",
      "    pred =  ['conended', 'conended', 'conended', 'conended']\n",
      "    chosen_data =  ['calculate', 'calculates', 'calculating', 'calculated']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  calculates\n",
      "pred_seq =  corleseted\n",
      "target_seq =  calculates\n",
      "-----------------\n",
      "Iter 34000: loss = 2.0595\n",
      "ce_loss =  2.0593907833099365\n",
      "kld_loss =  0.00014150142669677734\n",
      "    ==================\n",
      "    pred =  ['sentinged', 'sentinged', 'consentsed', 'sentinged']\n",
      "    chosen_data =  ['perceive', 'perceives', 'perceiving', 'perceived']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  perceived\n",
      "pred_seq =  crnehsned\n",
      "target_seq =  perceived\n",
      "-----------------\n",
      "Iter 35000: loss = 2.0841\n",
      "ce_loss =  2.0831000804901123\n",
      "kld_loss =  0.0009953975677490234\n",
      "    ==================\n",
      "    pred =  ['coneee', 'coneee', 'coneee', 'coneee']\n",
      "    chosen_data =  ['brag', 'brags', 'bragging', 'bragged']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  brags\n",
      "pred_seq =  ceage\n",
      "target_seq =  brags\n",
      "-----------------\n",
      "Iter 36000: loss = 2.7888\n",
      "ce_loss =  2.788551092147827\n",
      "kld_loss =  0.00024175643920898438\n",
      "    ==================\n",
      "    pred =  ['searee', 'searee', 'searee', 'searee']\n",
      "    chosen_data =  ['clamber', 'clambers', 'clambering', 'clambered']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  clambers\n",
      "pred_seq =  searee{\n",
      "target_seq =  clambers\n",
      "-----------------\n",
      "Iter 37000: loss = 1.5891\n",
      "ce_loss =  1.5890568494796753\n",
      "kld_loss =  2.98917293548584e-05\n",
      "    ==================\n",
      "    pred =  ['deseee', 'seeeee', 'arreste', 'asserse']\n",
      "    chosen_data =  ['fail', 'fails', 'failing', 'failed']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  failing\n",
      "pred_seq =  dorneng\n",
      "target_seq =  failing\n",
      "-----------------\n",
      "Iter 38000: loss = 3.4386\n",
      "ce_loss =  3.4384918212890625\n",
      "kld_loss =  0.000148087739944458\n",
      "    ==================\n",
      "    pred =  ['seeeees', 'seeeees', 'seeeees', 'seeeees']\n",
      "    chosen_data =  ['backtrack', 'backtracks', 'backtracking', 'backtracked']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  backtracked\n",
      "pred_seq =  seeeees{\n",
      "target_seq =  backtracked\n",
      "-----------------\n",
      "Iter 39000: loss = 1.9406\n",
      "ce_loss =  1.9401147365570068\n",
      "kld_loss =  0.0004528462886810303\n",
      "    ==================\n",
      "    pred =  ['seaesed', 'seaten', 'consented', 'consented']\n",
      "    chosen_data =  ['bind', 'binds', 'binding', 'bound']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  bound\n",
      "pred_seq =  sernt\n",
      "target_seq =  bound\n",
      "-----------------\n",
      "Iter 40000: loss = 1.9837\n",
      "ce_loss =  1.9835045337677002\n",
      "kld_loss =  0.0001512765884399414\n",
      "    ==================\n",
      "    pred =  ['arrested', 'destee', 'conte', 'destee']\n",
      "    chosen_data =  ['fear', 'fears', 'fearing', 'feared']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  fears\n",
      "pred_seq =  alrre\n",
      "target_seq =  fears\n",
      "-----------------\n",
      "Iter 41000: loss = 2.5609\n",
      "ce_loss =  2.560225248336792\n",
      "kld_loss =  0.0006577074527740479\n",
      "    ==================\n",
      "    pred =  ['contere', 'sentee', 'sentee', 'sentee']\n",
      "    chosen_data =  ['know', 'knows', 'knowing', 'knew']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  know\n",
      "pred_seq =  sneu\n",
      "target_seq =  know\n",
      "-----------------\n",
      "Iter 42000: loss = 2.0370\n",
      "ce_loss =  2.0368144512176514\n",
      "kld_loss =  0.00017341971397399902\n",
      "    ==================\n",
      "    pred =  ['suares', 'conten', 'conten', 'conten']\n",
      "    chosen_data =  ['characterize', 'characterizes', 'characterizing', 'characterized']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  characterizes\n",
      "pred_seq =  coansteedsned\n",
      "target_seq =  characterizes\n",
      "-----------------\n",
      "Iter 43000: loss = 1.8621\n",
      "ce_loss =  1.8616894483566284\n",
      "kld_loss =  0.0003820061683654785\n",
      "    ==================\n",
      "    pred =  ['sent', 'sent', 'sent', 'sent']\n",
      "    chosen_data =  ['protect', 'protects', 'protecting', 'protected']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  protect\n",
      "pred_seq =  srewert\n",
      "target_seq =  protect\n",
      "-----------------\n",
      "Iter 44000: loss = 2.0220\n",
      "ce_loss =  2.0220017433166504\n",
      "kld_loss =  2.4586915969848633e-05\n",
      "    ==================\n",
      "    pred =  ['singed', 'conee', 'conders', 'conee']\n",
      "    chosen_data =  ['illumine', 'illumines', 'illumining', 'illumined']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  illumining\n",
      "pred_seq =  cnlanpngng\n",
      "target_seq =  illumining\n",
      "-----------------\n",
      "Iter 45000: loss = 2.3004\n",
      "ce_loss =  2.3002374172210693\n",
      "kld_loss =  0.00015023350715637207\n",
      "    ==================\n",
      "    pred =  ['coneene', 'coneene', 'destreatened', 'coneene']\n",
      "    chosen_data =  ['associate', 'associates', 'associating', 'associated']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  associate\n",
      "pred_seq =  csterknte\n",
      "target_seq =  associate\n",
      "-----------------\n",
      "Iter 46000: loss = 1.8335\n",
      "ce_loss =  1.833502173423767\n",
      "kld_loss =  2.7447938919067383e-05\n",
      "    ==================\n",
      "    pred =  ['complied', 'complied', 'complied', 'complied']\n",
      "    chosen_data =  ['disregard', 'disregards', 'disregarding', 'disregarded']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  disregarding\n",
      "pred_seq =  cisteaeteeng\n",
      "target_seq =  disregarding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Iter 47000: loss = 1.9183\n",
      "ce_loss =  1.9179389476776123\n",
      "kld_loss =  0.0003822147846221924\n",
      "    ==================\n",
      "    pred =  ['serre', 'serre', 'serre', 'serre']\n",
      "    chosen_data =  ['suffuse', 'suffuses', 'suffusing', 'suffused']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  suffuse\n",
      "pred_seq =  serfere\n",
      "target_seq =  suffuse\n",
      "-----------------\n",
      "Iter 48000: loss = 1.6734\n",
      "ce_loss =  1.6732635498046875\n",
      "kld_loss =  9.736418724060059e-05\n",
      "    ==================\n",
      "    pred =  ['shantered', 'shantered', 'shantered', 'shantered']\n",
      "    chosen_data =  ['bounce', 'bounces', 'bouncing', 'bounced']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  bounces\n",
      "pred_seq =  seunted\n",
      "target_seq =  bounces\n",
      "-----------------\n",
      "Iter 49000: loss = 1.6302\n",
      "ce_loss =  1.6298900842666626\n",
      "kld_loss =  0.0003027915954589844\n",
      "    ==================\n",
      "    pred =  ['sumplied', 'souttin', 'souttin', 'souttin']\n",
      "    chosen_data =  ['expend', 'expends', 'expending', 'expended']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  expend\n",
      "pred_seq =  sxpert\n",
      "target_seq =  expend\n",
      "-----------------\n",
      "Iter 50000: loss = 1.7426\n",
      "ce_loss =  1.7425071001052856\n",
      "kld_loss =  5.8084726333618164e-05\n",
      "    ==================\n",
      "    pred =  ['setree', 'setree', 'setree', 'setree']\n",
      "    chosen_data =  ['precipitate', 'precipitates', 'precipitating', 'precipitated']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  precipitates\n",
      "pred_seq =  srosottneted\n",
      "target_seq =  precipitates\n",
      "-----------------\n",
      "Iter 51000: loss = 2.8623\n",
      "ce_loss =  2.8621020317077637\n",
      "kld_loss =  0.00024139881134033203\n",
      "    ==================\n",
      "    pred =  ['saulled', 'conste', 'saulled', 'saulled']\n",
      "    chosen_data =  ['deliver', 'delivers', 'delivering', 'delivered']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  deliver\n",
      "pred_seq =  contend{\n",
      "target_seq =  deliver\n",
      "-----------------\n",
      "Iter 52000: loss = 1.3255\n",
      "ce_loss =  1.3252532482147217\n",
      "kld_loss =  0.00026106834411621094\n",
      "    ==================\n",
      "    pred =  ['seeeie', 'seeeeing', 'souree', 'seeeie']\n",
      "    chosen_data =  ['intermingle', 'intermingles', 'intermingling', 'intermingled']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  intermingle\n",
      "pred_seq =  sngertingee\n",
      "target_seq =  intermingle\n",
      "-----------------\n",
      "Iter 53000: loss = 3.0914\n",
      "ce_loss =  3.091372013092041\n",
      "kld_loss =  3.1560659408569336e-05\n",
      "    ==================\n",
      "    pred =  ['constre', 'constre', 'constre', 'constre']\n",
      "    chosen_data =  ['remember', 'remembers', 'remembering', 'remembered']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  remembering\n",
      "pred_seq =  constre{\n",
      "target_seq =  remembering\n",
      "-----------------\n",
      "Iter 54000: loss = 3.1624\n",
      "ce_loss =  3.1619179248809814\n",
      "kld_loss =  0.000495612621307373\n",
      "    ==================\n",
      "    pred =  ['soone', 'seaie', 'soone', 'soote']\n",
      "    chosen_data =  ['discipline', 'disciplines', 'disciplining', 'disciplined']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  discipline\n",
      "pred_seq =  soote{\n",
      "target_seq =  discipline\n",
      "-----------------\n",
      "Iter 55000: loss = 1.6810\n",
      "ce_loss =  1.68079674243927\n",
      "kld_loss =  0.0002003312110900879\n",
      "    ==================\n",
      "    pred =  ['seare', 'asservendsed', 'seare', 'arreatinged']\n",
      "    chosen_data =  ['flatten', 'flattens', 'flattening', 'flattened']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  flattens\n",
      "pred_seq =  slaiterd\n",
      "target_seq =  flattens\n",
      "-----------------\n",
      "Iter 56000: loss = 1.8618\n",
      "ce_loss =  1.8617228269577026\n",
      "kld_loss =  5.665421485900879e-05\n",
      "    ==================\n",
      "    pred =  ['coneei', 'coneei', 'coneei', 'coneei']\n",
      "    chosen_data =  ['behave', 'behaves', 'behaving', 'behaved']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  behaving\n",
      "pred_seq =  celareng\n",
      "target_seq =  behaving\n",
      "-----------------\n",
      "Iter 57000: loss = 2.6080\n",
      "ce_loss =  2.6079115867614746\n",
      "kld_loss =  0.00010821223258972168\n",
      "    ==================\n",
      "    pred =  ['arraie', 'arrie', 'arrie', 'arrie']\n",
      "    chosen_data =  ['wet', 'wets', 'wetting', 'wetted']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  wets\n",
      "pred_seq =  airt\n",
      "target_seq =  wets\n",
      "-----------------\n",
      "Iter 58000: loss = 1.8771\n",
      "ce_loss =  1.8767708539962769\n",
      "kld_loss =  0.0002949237823486328\n",
      "    ==================\n",
      "    pred =  ['conining', 'conining', 'conining', 'surre']\n",
      "    chosen_data =  ['entitle', 'entitles', 'entitling', 'entitled']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  entitle\n",
      "pred_seq =  cxtecee\n",
      "target_seq =  entitle\n",
      "-----------------\n",
      "Iter 59000: loss = 2.7277\n",
      "ce_loss =  2.7276132106781006\n",
      "kld_loss =  6.917119026184082e-05\n",
      "    ==================\n",
      "    pred =  ['arreassing', 'arreassing', 'arreassing', 'snaress']\n",
      "    chosen_data =  ['coexist', 'coexists', 'coexisting', 'coexisted']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  coexists\n",
      "pred_seq =  snaress{\n",
      "target_seq =  coexists\n",
      "-----------------\n",
      "Iter 60000: loss = 2.3628\n",
      "ce_loss =  2.3625478744506836\n",
      "kld_loss =  0.0002276599407196045\n",
      "    ==================\n",
      "    pred =  ['suaree', 'suaree', 'suaree', 'suaree']\n",
      "    chosen_data =  ['hurl', 'hurls', 'hurling', 'hurled']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  hurls\n",
      "pred_seq =  sarri\n",
      "target_seq =  hurls\n",
      "-----------------\n",
      "Iter 61000: loss = 1.7565\n",
      "ce_loss =  1.7563976049423218\n",
      "kld_loss =  0.00014790892601013184\n",
      "    ==================\n",
      "    pred =  ['conee', 'conee', 'conee', 'conee']\n",
      "    chosen_data =  ['scoop', 'scoops', 'scooping', 'scooped']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  scooped\n",
      "pred_seq =  cirrned\n",
      "target_seq =  scooped\n",
      "-----------------\n",
      "Iter 62000: loss = 2.5104\n",
      "ce_loss =  2.510082721710205\n",
      "kld_loss =  0.0003058016300201416\n",
      "    ==================\n",
      "    pred =  ['sistri', 'sistri', 'seepts', 'seepts']\n",
      "    chosen_data =  ['festoon', 'festoons', 'festooning', 'festooned']\n",
      "    BLEU-4 score =  0\n",
      "    ==================\n",
      "input_seq =  festoons\n",
      "pred_seq =  sistri{\n",
      "target_seq =  festoons\n"
     ]
    }
   ],
   "source": [
    "loss_list, ce_loss_list, kld_loss_list, bleu_list = \\\n",
    "            trainIter_condVAE(my_vae, train_vocab, n_iters=2000000, \\\n",
    "                           print_every=1000, save_every=100000, record_every=500,\\\n",
    "                           learning_rate=lr,teacher_forcing_ratio=teacher_forcing_ratio, \\\n",
    "                           optimizer= optimizer, criterion_CE = VAE_Loss_CE, \\\n",
    "                           criterion_KLD = VAE_Loss_KLD,date = '_0813_2105')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kld_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(vae_model, data_pairs, num_eval_data ,criterion_CE = VAE_Loss_CE, criterion_KLD = VAE_Loss_KLD):\n",
    "    loss_list = []\n",
    "    ce_loss_list = []\n",
    "    kld_loss_list = []\n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    vae_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_eval_data):\n",
    "            # Seperate pair for input# Randomly generate testing pairs from data\n",
    "            chosen_data = random.choice(data)\n",
    "            input_tense = random.randint(0,3) # Draw input tense\n",
    "            target_tense = random.randint(0,3) # Draw target tense\n",
    "            input_seq, target_seq = (seq_from_str(chosen_data[input_tense]),seq_from_str(chosen_data[target_tense])) \n",
    "            \n",
    "            # Initialize hidden feature\n",
    "            hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, input_tense, target_tense)\n",
    "\n",
    "            # Ground truth should have EOS in the end\n",
    "            target_seq.append(EOS_token)\n",
    "\n",
    "            # Calculate loss\n",
    "            # First, we should strim the sequences by the length of smaller one\n",
    "            min_len = min(len(target_seq),len(result))\n",
    "            hat_y = result[:min_len]\n",
    "            y = torch.tensor(target_seq[:min_len], device=device)\n",
    "\n",
    "            ce_loss = criterion_CE(hat_y, y)\n",
    "            kld_loss = criterion_KLD(mu, logvar)\n",
    "            kld_loss = kld_loss # KL annealing\n",
    "\n",
    "            loss = ce_loss + kld_loss\n",
    "            \n",
    "            loss_list.append(loss)\n",
    "            ce_loss_list.append(ce_loss)\n",
    "            kld_loss_list.append(kld_loss)\n",
    "            \n",
    "\n",
    "            # Convert predicted result into str\n",
    "            pred_seq = str_from_tensor(hat_y)\n",
    "            print('-----------------')\n",
    "            print('loss = ', loss)\n",
    "            print('input_seq = ', chosen_data[input_tense])\n",
    "            print('pred_seq = ', pred_seq)\n",
    "            print('target_seq = ', chosen_data[target_tense])\n",
    "            \n",
    "\n",
    "    return loss_list, ce_loss_list, kld_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val(my_vae, train_vocab, num_eval_data= 200, criterion = VAE_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

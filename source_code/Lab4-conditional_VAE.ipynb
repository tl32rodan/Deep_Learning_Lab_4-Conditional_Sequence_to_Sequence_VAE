{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "from VAE import *\n",
    "from scores import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = load_data('./data/train.txt')\n",
    "test_vocab = load_data('./data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get different tense pairs\n",
    "### !Basically unused in conditional VAE training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tense_paris(train_vocab, input_tense, target_tense):\n",
    "    pairs = []\n",
    "\n",
    "    for vocabs in train_vocab:\n",
    "        pairs.append((vocabs[input_tense],vocabs[target_tense]))\n",
    "        \n",
    "    return pairs  \n",
    "\n",
    "# Simple Present -> Third Person\n",
    "train_st_tp  = get_tense_paris(train_vocab, 0, 1)\n",
    "# Simple Present -> Present Progressive\n",
    "train_st_pp  = get_tense_paris(train_vocab, 0, 2)\n",
    "# Simple Present -> Past\n",
    "train_st_past  = get_tense_paris(train_vocab, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 28 #The number of vocabulary\n",
    "SOS_token = 0\n",
    "EOS_token = vocab_size-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Hyper Parameters----------#\n",
    "hidden_size = 256\n",
    "latent_size = 64\n",
    "teacher_forcing_ratio = 0.75\n",
    "empty_input_ratio = 0.1\n",
    "KLD_weight = 0.0\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_from_str(target):\n",
    "    ord_a = ord('a')\n",
    "    seq = [ord(c) - ord_a + 1 for c in target]\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def str_from_tensor(target):\n",
    "    seq = ''\n",
    "    for output in target:\n",
    "        _, c = output.topk(1)\n",
    "        seq += chr(c+ord('a')-1)\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use KL annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_annealing(current_iter, policy = 'mono', reach_max = 100, period = 200):\n",
    "    if policy == 'mono':\n",
    "        beta = 1 if current_iter >= reach_max else current_iter/reach_max\n",
    "    elif policy == 'cyclical':\n",
    "        beta = 1 if current_iter%period >= reach_max else (current_iter%period)/reach_max\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 4 tense using simple present (for BLEU-4 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_by_simple(vae_model, data_tuple):\n",
    "    pred_tuple = []\n",
    "    \n",
    "    vae_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data_tuple)):\n",
    "            input_tense = 0  # Input: simple present\n",
    "            target_tense = i # Target: 4 tense results\n",
    "            input_seq, target_seq = (seq_from_str(data_tuple[input_tense]),seq_from_str(data_tuple[target_tense])) \n",
    "            \n",
    "            # Initialize hidden feature\n",
    "            hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, input_tense, target_tense)\n",
    "            \n",
    "            pred_seq = str_from_tensor(result)\n",
    "            pred_tuple.append(pred_seq[:-1])\n",
    "            \n",
    "    return pred_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_condVAE(vae_model, input_seq, input_cond, target_seq, target_cond, use_teacher_forcing, optimizer, \\\n",
    "                  criterion_CE, criterion_KLD, kl_annealing_beta = 1):    \n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize hidden feature\n",
    "    hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "        \n",
    "    # Run model\n",
    "    optimizer.zero_grad()\n",
    "    if use_teacher_forcing:\n",
    "        # input_cond is encoder condition; targer_cond is decoder condition\n",
    "        result, mu, logvar = vae_model(input_seq, hidden, input_cond, target_cond, use_teacher_forcing, target_seq)\n",
    "    else:\n",
    "        result, mu, logvar = vae_model(input_seq, hidden, input_cond, target_cond, use_teacher_forcing, None)\n",
    "            \n",
    "            \n",
    "    # Ground truth should have EOS in the end\n",
    "    target_seq.append(EOS_token)\n",
    "    \n",
    "    # Calculate loss\n",
    "    # First, we should strim the sequences by the length of smaller one\n",
    "    min_len = min(len(target_seq),len(result))\n",
    "        \n",
    "    # hat_y need not to do one-hot encoding\n",
    "    hat_y = result[:min_len]\n",
    "    y = torch.tensor(target_seq[:min_len], device=device)\n",
    "        \n",
    "    ce_loss = criterion_CE(hat_y, y)\n",
    "    kld_loss = criterion_KLD(mu, logvar)\n",
    "    #print('------------------------------')\n",
    "    #print('before: ',kld_loss )\n",
    "    kld_loss = kl_annealing_beta * kld_loss # KL annealing\n",
    "    #print('after: ',kld_loss )\n",
    "    \n",
    "    loss = ce_loss + kld_loss\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return ce_loss.item(), kld_loss.item(), hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIter_condVAE(vae_model, data, n_epochs, print_every=100, save_every=100, record_every=1,\n",
    "                      learning_rate=0.01, teacher_forcing_ratio = 1.0, \n",
    "                      optimizer = None, scheduler = None,\n",
    "                      criterion_CE = VAE_Loss_CE, criterion_KLD = VAE_Loss_KLD,\n",
    "                      date = '', kl_annealing = 'mono'):\n",
    "    '''\n",
    "        data: A list of 4-tuple\n",
    "              the tense order should be : (simple present, third person, present progressive, past)\n",
    "    '''\n",
    "    loss_list = []\n",
    "    ce_loss_list = []\n",
    "    kld_loss_list = []\n",
    "    bleu_list = []\n",
    "  \n",
    "    # Check optimizer; default: SGD\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.SGD(vae_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        # Shuffle data\n",
    "        data_tuples = data[:]\n",
    "        random.shuffle(data_tuples)\n",
    "        \n",
    "        avg_bleu = 0.\n",
    "        avg_loss = 0.\n",
    "        avg_ce   = 0.\n",
    "        avg_kld  = 0.\n",
    "        \n",
    "        # KL annealing\n",
    "        #beta = KL_annealing(i, policy=kl_annealing)\n",
    "        beta = 1e-4\n",
    "        #print('beta = ',beta)\n",
    "        \n",
    "        for data_tuple in data_tuples:\n",
    "            \n",
    "            # Calculate BLEU-4 score\n",
    "            # Should execute before updating the model\n",
    "            pred = infer_by_simple(vae_model, data_tuple)\n",
    "            avg_bleu += compute_bleu(pred, data_tuple)\n",
    "            \n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    input_tense = i # input tense\n",
    "                    target_tense = j# target tense\n",
    "                    input_seq = seq_from_str(data_tuple[input_tense])\n",
    "                    target_seq = seq_from_str(data_tuple[target_tense])                  \n",
    "                    # Determine whether to use teacher forcing\n",
    "                    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "                    # Training\n",
    "                    vae_model.train()\n",
    "                    ce_loss, kld_loss, hat_y = train_condVAE(vae_model, input_seq, input_tense,\\\n",
    "                                                             target_seq, target_tense,\\\n",
    "                                                             use_teacher_forcing, optimizer, \\\n",
    "                                                             criterion_CE, criterion_KLD, beta)\n",
    "                    # Loss\n",
    "                    loss = ce_loss + kld_loss\n",
    "                    #print('loss = ',loss,'; ce_loss = ', ce_loss, '; kld_loss = ',kld_loss)\n",
    "                    avg_loss += loss\n",
    "                    avg_ce   += ce_loss\n",
    "                    avg_kld  += kld_loss\n",
    "\n",
    "                    if scheduler is not None:\n",
    "                        scheduler.step(loss)\n",
    "                    \n",
    "        \n",
    "        \n",
    "        avg_bleu = avg_bleu/(len(data)*4)\n",
    "        avg_loss = avg_loss/(len(data)*4)\n",
    "        avg_ce   = avg_ce/(len(data)*4)\n",
    "        avg_kld  = avg_kld/(len(data)*4)\n",
    "        \n",
    "        if (epoch+1) % record_every == 0:\n",
    "            loss_list.append(avg_loss)\n",
    "            ce_loss_list.append(avg_ce)\n",
    "            kld_loss_list.append(avg_kld)\n",
    "            bleu_list.append(avg_bleu)\n",
    "            \n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print('-----------------')\n",
    "            print('Iter %d: avg_loss = %.4f' % (epoch+1, avg_loss))\n",
    "            print('Avg CE = ', avg_ce)\n",
    "            print('Avg KLD = ', avg_kld)\n",
    "            print('Beta = ',beta)\n",
    "            print('Avg BLEU-4 score = ', avg_bleu)\n",
    "            data_tuple = random.choice(data)\n",
    "            pred_seq = infer_by_simple(vae_model, data_tuple)\n",
    "            \n",
    "            print('=========================')\n",
    "            print('|| pred_seq = ', pred_seq)\n",
    "            print('|| target_seq = ', data_tuple)\n",
    "            print('=========================')\n",
    "            \n",
    "        if (epoch+1) % save_every == 0:\n",
    "            torch.save(vae_model,'./models/condVAE_'+str(epoch+1)+date)\n",
    "    \n",
    "    return loss_list, ce_loss_list, kld_loss_list, bleu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vae = CondVAE(vocab_size, hidden_size, vocab_size, teacher_forcing_ratio).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(my_vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c274f7c38cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_CE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE_Loss_CE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                            criterion_KLD = VAE_Loss_KLD,date = '_0813_2105')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-620b41683c3d>\u001b[0m in \u001b[0;36mtrainIter_condVAE\u001b[0;34m(vae_model, data, n_epochs, print_every, save_every, record_every, learning_rate, teacher_forcing_ratio, optimizer, scheduler, criterion_CE, criterion_KLD, date, kl_annealing)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Calculate BLEU-4 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Should execute before updating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_by_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mavg_bleu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompute_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ddca924b43ed>\u001b[0m in \u001b[0;36minfer_by_simple\u001b[0;34m(vae_model, data_tuple)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab4/source_code/VAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden, encode_cond, decode_cond, use_teacher_forcing, target_tensor)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Reparameterize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab4/source_code/VAE.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input_seq, hidden, encode_cond)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0minput_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mmu\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab4/source_code/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list, ce_loss_list, kld_loss_list, bleu_list = \\\n",
    "            trainIter_condVAE(my_vae, train_vocab, n_epochs=50, \\\n",
    "                           print_every=1, save_every=1000, record_every=1,\\\n",
    "                           learning_rate=lr,teacher_forcing_ratio=teacher_forcing_ratio, \\\n",
    "                           optimizer= optimizer, criterion_CE = VAE_Loss_CE, \\\n",
    "                           criterion_KLD = VAE_Loss_KLD,date = '_0813_2105')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kld_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(vae_model, data_pairs, num_eval_data ,criterion_CE = VAE_Loss_CE, criterion_KLD = VAE_Loss_KLD):\n",
    "    loss_list = []\n",
    "    ce_loss_list = []\n",
    "    kld_loss_list = []\n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    vae_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_eval_data):\n",
    "            # Seperate pair for input# Randomly generate testing pairs from data\n",
    "            chosen_data = random.choice(data)\n",
    "            input_tense = random.randint(0,3) # Draw input tense\n",
    "            target_tense = random.randint(0,3) # Draw target tense\n",
    "            input_seq, target_seq = (seq_from_str(chosen_data[input_tense]),seq_from_str(chosen_data[target_tense])) \n",
    "            \n",
    "            # Initialize hidden feature\n",
    "            hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, input_tense, target_tense)\n",
    "\n",
    "            # Ground truth should have EOS in the end\n",
    "            target_seq.append(EOS_token)\n",
    "\n",
    "            # Calculate loss\n",
    "            # First, we should strim the sequences by the length of smaller one\n",
    "            min_len = min(len(target_seq),len(result))\n",
    "            hat_y = result[:min_len]\n",
    "            y = torch.tensor(target_seq[:min_len], device=device)\n",
    "\n",
    "            ce_loss = criterion_CE(hat_y, y)\n",
    "            kld_loss = criterion_KLD(mu, logvar)\n",
    "            kld_loss = kld_loss # KL annealing\n",
    "\n",
    "            loss = ce_loss + kld_loss\n",
    "            \n",
    "            loss_list.append(loss)\n",
    "            ce_loss_list.append(ce_loss)\n",
    "            kld_loss_list.append(kld_loss)\n",
    "            \n",
    "\n",
    "            # Convert predicted result into str\n",
    "            pred_seq = str_from_tensor(hat_y)\n",
    "            print('-----------------')\n",
    "            print('loss = ', loss)\n",
    "            print('input_seq = ', chosen_data[input_tense])\n",
    "            print('pred_seq = ', pred_seq)\n",
    "            print('target_seq = ', chosen_data[target_tense])\n",
    "            \n",
    "\n",
    "    return loss_list, ce_loss_list, kld_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val(my_vae, train_vocab, num_eval_data= 200, criterion = VAE_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

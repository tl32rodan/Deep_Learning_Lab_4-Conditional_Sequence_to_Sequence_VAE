{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from os import system\n",
    "from dataloader import *\n",
    "from VAE import *\n",
    "from scores import *\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = load_data('./data/train.txt')\n",
    "test_vocab = load_data('./data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get different tense pairs for (unconditional) VAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tense_paris(train_vocab, source_index, target_index):\n",
    "    pairs = []\n",
    "\n",
    "    for vocabs in train_vocab:\n",
    "        pairs.append((vocabs[source_index],vocabs[target_index]))\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Present -> Third Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st_tp  = get_tense_paris(train_vocab, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Present -> Present Progressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st_pp  = get_tense_paris(train_vocab, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Present -> Past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st_past  = get_tense_paris(train_vocab, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqFromPair(pair):\n",
    "    ord_a = ord('a')\n",
    "    input_seq = [ord(c) - ord_a + 1 for c in pair[0]]\n",
    "    target_seq = [ord(c) - ord_a + 1 for c in pair[1]]\n",
    "    \n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehot(idx,num_classes=vocab_size):\n",
    "    return torch.zeros(len(idx), num_classes).scatter_(1, idx.unsqueeze(1), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 28 #The number of vocabulary\n",
    "SOS_token = 0\n",
    "EOS_token = vocab_size-1\n",
    "\n",
    "def train(vae_model, data_pairs, n_iters, print_every=1000, learning_rate=0.01, teacher_forcing_ratio = 1.0,\\\n",
    "         optimizer = None):\n",
    "    loss_list = []\n",
    "    \n",
    "    # Randomly generate training pairs from data\n",
    "    training_pairs = [seqFromPair(random.choice(data_pairs))\n",
    "                      for i in range(n_iters)]    \n",
    "    \n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Check optimizer; default: SGD\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.SGD(vae_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        # Initialize hidden feature\n",
    "        hidden = torch.zeros(1, 1, hidden_size, device=device)\n",
    "        \n",
    "        # Seperate pair for input\n",
    "        input_seq, target_seq = training_pairs[i]   \n",
    "        \n",
    "        # Determine whether to use teacher forcing\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        \n",
    "        # Run model\n",
    "        if use_teacher_forcing:\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, use_teacher_forcing, target_seq)\n",
    "        else:\n",
    "            result, mu, logvar = vae_model(input_seq, hidden, use_teacher_forcing, None)\n",
    "            \n",
    "        # ground truth should add EOS in the end\n",
    "        target_seq.append(EOS_token)\n",
    "        \n",
    "        # Calculate loss\n",
    "        min_len = min(len(target_seq),len(result))\n",
    "        \n",
    "        #-------- make_onehot will have problem back-propagating.. --------#\n",
    "        hat_y = make_onehot(result[:min_len])\n",
    "        y = make_onehot(target_seq[:min_len])\n",
    "            \n",
    "        loss = VAE_Loss(hat_y, y, mu, logvar)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if i % print_every == 0:\n",
    "            print('Iter %d: loss = %.4f' % (i, loss))\n",
    "    \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Hyper Parameters----------#\n",
    "hidden_size = 256\n",
    "teacher_forcing_ratio = 1.0\n",
    "empty_input_ratio = 0.1\n",
    "KLD_weight = 0.0\n",
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vae = VAE(vocab_size, hidden_size, vocab_size, teacher_forcing_ratio).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(my_vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Simple Present -> Present Progressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Function AddBackward0 returned an invalid gradient at index 1 - expected type TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) (validate_outputs at /pytorch/torch/csrc/autograd/engine.cpp:484)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f6c80de3536 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2d83d24 (0x7f6c63fe7d24 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f6c63fe9858 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f6c63feb7e2 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f6c63fe3e59 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f6c81b6a5f8 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f6c94e0f19d in /opt/conda/bin/../lib/libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f6c983d66db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f6c980ffa3f in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ad54a8539862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train(my_vae, train_st_pp, n_iters=100, print_every=1, learning_rate=lr, \\\n\u001b[0;32m----> 2\u001b[0;31m       teacher_forcing_ratio=teacher_forcing_ratio, optimizer= optimizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-7dc5ecc84ed7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(vae_model, data_pairs, n_iters, print_every, learning_rate, teacher_forcing_ratio, optimizer)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function AddBackward0 returned an invalid gradient at index 1 - expected type TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) (validate_outputs at /pytorch/torch/csrc/autograd/engine.cpp:484)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f6c80de3536 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2d83d24 (0x7f6c63fe7d24 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f6c63fe9858 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f6c63feb7e2 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f6c63fe3e59 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f6c81b6a5f8 in /home/tl32rodan/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f6c94e0f19d in /opt/conda/bin/../lib/libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f6c983d66db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f6c980ffa3f in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "train(my_vae, train_st_pp, n_iters=100, print_every=1, learning_rate=lr, \\\n",
    "      teacher_forcing_ratio=teacher_forcing_ratio, optimizer= optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
